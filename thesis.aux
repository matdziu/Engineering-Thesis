\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{kpmg_alco}
\citation{kpmg_alco}
\@writefile{toc}{\contentsline {section}{\numberline {1}Problem definition}{1}{section.1}}
\newlabel{problem_definition}{{1}{1}{Problem definition}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A large beer shelf. Source: \url {http://trib.com}.}}{1}{figure.1}}
\newlabel{fig:beer_shelf}{{1}{1}{A large beer shelf. Source: \protect \url {http://trib.com}}{figure.1}{}}
\citation{survey}
\@writefile{toc}{\contentsline {section}{\numberline {2}Solution overview}{2}{section.2}}
\newlabel{solution_overview}{{2}{2}{Solution overview}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Weighted average of respondents' answers (chart). For choosing an option as first - weight: 4, for choosing an option as second - weight: 3 etc. Obtained sum is then divided by total number of respondents (here: 50).}}{2}{figure.2}}
\newlabel{fig:survey_chart}{{2}{2}{Weighted average of respondents' answers (chart). For choosing an option as first - weight: 4, for choosing an option as second - weight: 3 etc. Obtained sum is then divided by total number of respondents (here: 50)}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Weighted average of respondents' answers (table with details). For method of average calculation see: \autoref  {fig:survey_chart}.}}{2}{figure.3}}
\newlabel{fig:survey_table}{{3}{2}{Weighted average of respondents' answers (table with details). For method of average calculation see: \autoref {fig:survey_chart}}{figure.3}{}}
\citation{android_guide}
\citation{flask_docs}
\citation{firebase_database_docs}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Server-client recognition system for beer labels with functional principle (consecutive steps enumerated).}}{3}{figure.4}}
\newlabel{fig:scheme}{{4}{3}{Server-client recognition system for beer labels with functional principle (consecutive steps enumerated)}{figure.4}{}}
\citation{ai_modern_approach}
\citation{cpu_vs_gpu}
\@writefile{toc}{\contentsline {section}{\numberline {3}Introduction to Artificial Intelligence}{4}{section.3}}
\newlabel{introduction_to_ai}{{3}{4}{Introduction to Artificial Intelligence}{section.3}{}}
\citation{cisco_era}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Performance of NVIDIA GPUs and Intel CPUs measured in GFLOP/s \cite  {cpu_vs_gpu}.}}{5}{figure.5}}
\newlabel{fig:cpu_gpu}{{5}{5}{Performance of NVIDIA GPUs and Intel CPUs measured in GFLOP/s \cite {cpu_vs_gpu}}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Global IP traffic by devices \cite  {cisco_era} with 24\% compound annual growth rate (2016-2021).}}{5}{figure.6}}
\newlabel{fig:cisco_era}{{6}{5}{Global IP traffic by devices \cite {cisco_era} with 24\% compound annual growth rate (2016-2021)}{figure.6}{}}
\citation{ai_modern_approach}
\@writefile{toc}{\contentsline {section}{\numberline {4}Introduction to Neural Networks}{6}{section.4}}
\newlabel{introduction_to_nn}{{4}{6}{Introduction to Neural Networks}{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A simple neural network with one hidden layer (a layer between inputs and outputs).}}{6}{figure.7}}
\newlabel{fig:no_activation_net}{{7}{6}{A simple neural network with one hidden layer (a layer between inputs and outputs)}{figure.7}{}}
\newlabel{eq:y_hat_1}{{1}{6}{Introduction to Neural Networks}{equation.4.1}{}}
\newlabel{eq:y_hat_2}{{2}{6}{Introduction to Neural Networks}{equation.4.2}{}}
\newlabel{eq:in_1}{{3}{6}{Introduction to Neural Networks}{equation.4.3}{}}
\newlabel{eq:in_2}{{4}{6}{Introduction to Neural Networks}{equation.4.4}{}}
\newlabel{eq:in_3}{{5}{6}{Introduction to Neural Networks}{equation.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Exemplary classifier input, output and desired (one-hot encoded) output with legend.}}{7}{figure.8}}
\newlabel{fig:probability_vectors}{{8}{7}{Exemplary classifier input, output and desired (one-hot encoded) output with legend}{figure.8}{}}
\newlabel{eq:cross_entropy}{{6}{7}{Introduction to Neural Networks}{equation.4.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Updated model of simple neural network from \autoref  {fig:no_activation_net}. $g$ is a sigmoid activation function. Outputs are often normalized using softmax.}}{8}{figure.9}}
\newlabel{fig:activation_net}{{9}{8}{Updated model of simple neural network from \autoref {fig:no_activation_net}. $g$ is a sigmoid activation function. Outputs are often normalized using softmax}{figure.9}{}}
\newlabel{eq:sigmoid}{{7}{8}{Introduction to Neural Networks}{equation.4.7}{}}
\newlabel{eq:softmax}{{8}{8}{Introduction to Neural Networks}{equation.4.8}{}}
\newlabel{eq:update_rule}{{9}{8}{Introduction to Neural Networks}{equation.4.9}{}}
\citation{chain_rule_def}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces A simple neural network, with sigmoid activation function $g$ (\autoref  {eq:sigmoid}), i. e. $a_1^{(2)}=g(w_{11}^{(1)}x_1)$.}}{9}{figure.10}}
\newlabel{fig:simple_net}{{10}{9}{A simple neural network, with sigmoid activation function $g$ (\autoref {eq:sigmoid}), i. e. $a_1^{(2)}=g(w_{11}^{(1)}x_1)$}{figure.10}{}}
\newlabel{eq:inference}{{10}{9}{Introduction to Neural Networks}{equation.4.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Outline of a single step of backpropagation with chain rule, where $E=-y_1log(\mathaccentV {hat}05E{y_1})$. Value $y_1$ is a desired binary output from training set.}}{9}{figure.11}}
\newlabel{fig:backprop}{{11}{9}{Outline of a single step of backpropagation with chain rule, where $E=-y_1log(\hat {y_1})$. Value $y_1$ is a desired binary output from training set}{figure.11}{}}
\newlabel{eq:gradient_1}{{11}{9}{Introduction to Neural Networks}{equation.4.11}{}}
\newlabel{eq:gradient_2}{{12}{9}{Introduction to Neural Networks}{equation.4.12}{}}
\citation{lecun_object}
\@writefile{toc}{\contentsline {section}{\numberline {5}Introduction to Convolutional Neural Networks}{11}{section.5}}
\newlabel{introduction_to_cnns}{{5}{11}{Introduction to Convolutional Neural Networks}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Grayscale image of number 7 (4 x 4 pixels resolution).}}{11}{figure.12}}
\newlabel{fig:input}{{12}{11}{Grayscale image of number 7 (4 x 4 pixels resolution)}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Regular neural network recognizing number 7 in image input from \autoref  {fig:input}, which is deconstructed (flattened) into vector of size 16.}}{11}{figure.13}}
\newlabel{fig:regular_net_image}{{13}{11}{Regular neural network recognizing number 7 in image input from \autoref {fig:input}, which is deconstructed (flattened) into vector of size 16}{figure.13}{}}
\citation{lecun_object}
\citation{rgb_def}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces A number from \autoref  {fig:input} divided into four pixel regions.}}{12}{figure.14}}
\newlabel{fig:segmented_input}{{14}{12}{A number from \autoref {fig:input} divided into four pixel regions}{figure.14}{}}
\newlabel{eq:relu}{{13}{12}{Introduction to Convolutional Neural Networks}{equation.5.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Local connectivity of inputs from \autoref  {fig:segmented_input} to hidden nodes (vector form).}}{13}{figure.15}}
\newlabel{fig:cnn_column}{{15}{13}{Local connectivity of inputs from \autoref {fig:segmented_input} to hidden nodes (vector form)}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Local connectivity of inputs from \autoref  {fig:segmented_input} to hidden nodes (matrix form).}}{13}{figure.16}}
\newlabel{fig:cnn_spacial}{{16}{13}{Local connectivity of inputs from \autoref {fig:segmented_input} to hidden nodes (matrix form)}{figure.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces LeNet-5 CNN \cite  {lecun_object} used for handwritten digit recognition.}}{13}{figure.17}}
\newlabel{fig:lecun_net}{{17}{13}{LeNet-5 CNN \cite {lecun_object} used for handwritten digit recognition}{figure.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Consecutive steps of convolution using filter of size 2x2 with stride 2 (coefficients visible in red in the bottom right corner of a filter). The pink matrix is called a feature map and in this case represents a convolutional layer.}}{14}{figure.18}}
\newlabel{fig:convolution}{{18}{14}{Consecutive steps of convolution using filter of size 2x2 with stride 2 (coefficients visible in red in the bottom right corner of a filter). The pink matrix is called a feature map and in this case represents a convolutional layer}{figure.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Consecutive steps of max pooling with window of size 2x2 and stride 2. Green matrix is a reduced tensor.}}{14}{figure.19}}
\newlabel{fig:max_pooling}{{19}{14}{Consecutive steps of max pooling with window of size 2x2 and stride 2. Green matrix is a reduced tensor}{figure.19}{}}
\citation{synset_def}
\citation{canziani_analysis}
\citation{canziani_analysis}
\citation{canziani_analysis}
\citation{canziani_analysis}
\@writefile{toc}{\contentsline {section}{\numberline {6}Comparison of world-class CNN architectures}{15}{section.6}}
\newlabel{comparison_ccn_archs}{{6}{15}{Comparison of world-class CNN architectures}{section.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Comparison of world-class CNN architectures \cite  {canziani_analysis} including: top-1 accuracy, number of operations and parameters.}}{15}{figure.20}}
\newlabel{fig:world_cnns}{{20}{15}{Comparison of world-class CNN architectures \cite {canziani_analysis} including: top-1 accuracy, number of operations and parameters}{figure.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Transfer learning}{16}{section.7}}
\newlabel{transfer_learning}{{7}{16}{Transfer learning}{section.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Advanced CNN without last fully connected layer.}}{16}{figure.21}}
\newlabel{fig:tl_sliced_net}{{21}{16}{Advanced CNN without last fully connected layer}{figure.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Inference of one image (pink matrix) from training set using advanced CNN with sliced layer and pre-trained weights. The output (green vector) is a bottleneck feature i. e. this CNN's representation of a given image.}}{17}{figure.22}}
\newlabel{fig:obtain_bottleneck}{{22}{17}{Inference of one image (pink matrix) from training set using advanced CNN with sliced layer and pre-trained weights. The output (green vector) is a bottleneck feature i. e. this CNN's representation of a given image}{figure.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Inference in second (mediocre) neural network used in transfer learning, which is trained on labeled bottleneck features, with labeling illustrated below.}}{17}{figure.23}}
\newlabel{fig:using_bottleneck}{{23}{17}{Inference in second (mediocre) neural network used in transfer learning, which is trained on labeled bottleneck features, with labeling illustrated below}{figure.23}{}}
\citation{hsv_def}
\@writefile{toc}{\contentsline {section}{\numberline {8}Data augmentation}{18}{section.8}}
\newlabel{data_augmentation}{{8}{18}{Data augmentation}{section.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Data augmentation applied on a single STOP sign image.}}{18}{figure.24}}
\newlabel{fig:augm_ex}{{24}{18}{Data augmentation applied on a single STOP sign image}{figure.24}{}}
\newlabel{eq:horizontal_shear}{{14}{18}{Data augmentation}{equation.8.14}{}}
\newlabel{eq:vertical_shear}{{15}{18}{Data augmentation}{equation.8.15}{}}
\citation{retrofit_repo}
\citation{rxjava_repo}
\citation{kotlin_blogpost}
\citation{nosql_def}
\citation{rest_def}
\@writefile{toc}{\contentsline {section}{\numberline {9}Solution walkthrough}{19}{section.9}}
\newlabel{solution_walkthrough}{{9}{19}{Solution walkthrough}{section.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Main screen of Android application. Note the hints given to the user, resulting from prototype's limitations, namely: poor support of advanced searching in Firebase Realtime Database and high risk of wrong prediction given beer label image with a lot of background.}}{20}{figure.25}}
\newlabel{fig:app}{{25}{20}{Main screen of Android application. Note the hints given to the user, resulting from prototype's limitations, namely: poor support of advanced searching in Firebase Realtime Database and high risk of wrong prediction given beer label image with a lot of background}{figure.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Firebase Realtime Database with encoded key-value pairs of beer information.}}{20}{figure.26}}
\newlabel{fig:firebase_data}{{26}{20}{Firebase Realtime Database with encoded key-value pairs of beer information}{figure.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Terminal view of requests sent to Flask server (to "/predict" endpoint) from Android application. "200" return code indicates that request succeeded.}}{21}{figure.27}}
\newlabel{fig:terminal_server}{{27}{21}{Terminal view of requests sent to Flask server (to "/predict" endpoint) from Android application. "200" return code indicates that request succeeded}{figure.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Regular fully-connected neural network, which accuracy increased due to transfer learning based on Inception-V3. Values in brackets represent amount of neurons in each layer. Whereas number of neurons in hidden layers (f. c. layers) is fixed, inputs and outputs depend, respectively, on size of bottleneck features coming from Inception-V3 and number of beers CNN can recognize (in basic version of prototype it's 10). Both hidden layers use ReLU activation function.}}{21}{figure.28}}
\newlabel{fig:worse_net}{{28}{21}{Regular fully-connected neural network, which accuracy increased due to transfer learning based on Inception-V3. Values in brackets represent amount of neurons in each layer. Whereas number of neurons in hidden layers (f. c. layers) is fixed, inputs and outputs depend, respectively, on size of bottleneck features coming from Inception-V3 and number of beers CNN can recognize (in basic version of prototype it's 10). Both hidden layers use ReLU activation function}{figure.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Testing}{22}{section.10}}
\newlabel{testing}{{10}{22}{Testing}{section.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Related solutions}{23}{section.11}}
\newlabel{related_solutions}{{11}{23}{Related solutions}{section.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12}Conclusions}{24}{section.12}}
\newlabel{conclusions}{{12}{24}{Conclusions}{section.12}{}}
\bibdata{mybib}
\bibcite{hsv_def}{1}
\bibcite{kotlin_blogpost}{2}
\bibcite{nosql_def}{3}
\bibcite{rest_def}{4}
\bibcite{retrofit_repo}{5}
\bibcite{rxjava_repo}{6}
\bibcite{synset_def}{7}
\bibcite{android_guide}{8}
\bibcite{firebase_database_docs}{9}
\bibcite{flask_docs}{10}
\bibcite{survey}{11}
\bibcite{cpu_vs_gpu}{12}
\bibcite{chain_rule_def}{13}
\bibcite{rgb_def}{14}
\bibcite{canziani_analysis}{15}
\bibcite{cisco_era}{16}
\bibcite{kpmg_alco}{17}
\bibcite{lecun_object}{18}
\bibcite{ai_modern_approach}{19}
\bibstyle{siam}
