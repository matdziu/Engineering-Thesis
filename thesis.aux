\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\catcode `"\active 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{kpmg_alco}
\@writefile{toc}{\contentsline {section}{\numberline {1}Problem definition}{1}{section.1}}
\newlabel{problem_definition}{{1}{1}{Problem definition}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A large beer shelf. Source: \url {http://trib.com}.}}{1}{figure.1}}
\newlabel{fig:beer_shelf}{{1}{1}{A large beer shelf. Source: \protect \url {http://trib.com}}{figure.1}{}}
\citation{survey}
\citation{android_guide}
\citation{flask_docs}
\@writefile{toc}{\contentsline {section}{\numberline {2}Solution overview}{2}{section.2}}
\newlabel{solution_overview}{{2}{2}{Solution overview}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Weighted average of respondents' answers (chart). For choosing an option as first - weight: 4, for choosing an option as second - weight: 3 etc. Obtained sum is then divided by total number of respondents (here: 50).}}{2}{figure.2}}
\newlabel{fig:survey_chart}{{2}{2}{Weighted average of respondents' answers (chart). For choosing an option as first - weight: 4, for choosing an option as second - weight: 3 etc. Obtained sum is then divided by total number of respondents (here: 50)}{figure.2}{}}
\citation{firebase_database_docs}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Weighted average of respondents' answers (table with details). For method of average calculation see: \autoref  {fig:survey_chart}.}}{3}{figure.3}}
\newlabel{fig:survey_table}{{3}{3}{Weighted average of respondents' answers (table with details). For method of average calculation see: \autoref {fig:survey_chart}}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Server-client recognition system for beer labels with functional principle (consecutive steps enumerated).}}{3}{figure.4}}
\newlabel{fig:scheme}{{4}{3}{Server-client recognition system for beer labels with functional principle (consecutive steps enumerated)}{figure.4}{}}
\citation{lowe_sift}
\citation{beer_sift}
\citation{barcode_mobile}
\citation{lean_startup}
\@writefile{toc}{\contentsline {section}{\numberline {3}Related solutions}{4}{section.3}}
\newlabel{related_solutions}{{3}{4}{Related solutions}{section.3}{}}
\citation{ai_modern_approach}
\citation{cpu_vs_gpu}
\citation{cisco_era}
\@writefile{toc}{\contentsline {section}{\numberline {4}Introduction to Artificial Intelligence}{5}{section.4}}
\newlabel{introduction_to_ai}{{4}{5}{Introduction to Artificial Intelligence}{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Performance of NVIDIA GPUs and Intel CPUs measured in GFLOP/s \cite  {cpu_vs_gpu}.}}{6}{figure.5}}
\newlabel{fig:cpu_gpu}{{5}{6}{Performance of NVIDIA GPUs and Intel CPUs measured in GFLOP/s \cite {cpu_vs_gpu}}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Global IP traffic by devices \cite  {cisco_era} with 24\% compound annual growth rate (2016-2021).}}{6}{figure.6}}
\newlabel{fig:cisco_era}{{6}{6}{Global IP traffic by devices \cite {cisco_era} with 24\% compound annual growth rate (2016-2021)}{figure.6}{}}
\citation{ai_modern_approach}
\@writefile{toc}{\contentsline {section}{\numberline {5}Introduction to Neural Networks}{7}{section.5}}
\newlabel{introduction_to_nn}{{5}{7}{Introduction to Neural Networks}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A simple neural network with one hidden layer (a layer between inputs and outputs).}}{7}{figure.7}}
\newlabel{fig:no_activation_net}{{7}{7}{A simple neural network with one hidden layer (a layer between inputs and outputs)}{figure.7}{}}
\newlabel{eq:y_hat_1}{{1}{7}{Introduction to Neural Networks}{equation.5.1}{}}
\newlabel{eq:y_hat_2}{{2}{7}{Introduction to Neural Networks}{equation.5.2}{}}
\newlabel{eq:in_1}{{3}{7}{Introduction to Neural Networks}{equation.5.3}{}}
\newlabel{eq:in_2}{{4}{7}{Introduction to Neural Networks}{equation.5.4}{}}
\newlabel{eq:in_3}{{5}{7}{Introduction to Neural Networks}{equation.5.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Exemplary classifier input, output and desired (one-hot encoded) output with legend.}}{8}{figure.8}}
\newlabel{fig:probability_vectors}{{8}{8}{Exemplary classifier input, output and desired (one-hot encoded) output with legend}{figure.8}{}}
\newlabel{eq:cross_entropy}{{6}{8}{Introduction to Neural Networks}{equation.5.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Updated model of simple neural network from \autoref  {fig:no_activation_net}. $g$ is a sigmoid activation function. Outputs are often normalized using softmax.}}{9}{figure.9}}
\newlabel{fig:activation_net}{{9}{9}{Updated model of simple neural network from \autoref {fig:no_activation_net}. $g$ is a sigmoid activation function. Outputs are often normalized using softmax}{figure.9}{}}
\newlabel{eq:sigmoid}{{7}{9}{Introduction to Neural Networks}{equation.5.7}{}}
\newlabel{eq:softmax}{{8}{9}{Introduction to Neural Networks}{equation.5.8}{}}
\citation{chain_rule_def}
\newlabel{eq:update_rule}{{9}{10}{Introduction to Neural Networks}{equation.5.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces A simple neural network, with sigmoid activation function $g$ (\autoref  {eq:sigmoid}), i. e. $a_1^{(2)}=g(w_{11}^{(1)}x_1)$.}}{10}{figure.10}}
\newlabel{fig:simple_net}{{10}{10}{A simple neural network, with sigmoid activation function $g$ (\autoref {eq:sigmoid}), i. e. $a_1^{(2)}=g(w_{11}^{(1)}x_1)$}{figure.10}{}}
\newlabel{eq:inference}{{10}{10}{Introduction to Neural Networks}{equation.5.10}{}}
\newlabel{eq:gradient_1}{{11}{10}{Introduction to Neural Networks}{equation.5.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Outline of a single step of backpropagation with chain rule, where $E=-y_1log(\mathaccentV {hat}05E{y_1})$. Value $y_1$ is a desired binary output from training set.}}{11}{figure.11}}
\newlabel{fig:backprop}{{11}{11}{Outline of a single step of backpropagation with chain rule, where $E=-y_1log(\hat {y_1})$. Value $y_1$ is a desired binary output from training set}{figure.11}{}}
\newlabel{eq:gradient_2}{{12}{11}{Introduction to Neural Networks}{equation.5.12}{}}
\citation{lecun_object}
\@writefile{toc}{\contentsline {section}{\numberline {6}Introduction to Convolutional Neural Networks}{12}{section.6}}
\newlabel{introduction_to_cnns}{{6}{12}{Introduction to Convolutional Neural Networks}{section.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Grayscale image of number 7 (4 x 4 pixels resolution).}}{12}{figure.12}}
\newlabel{fig:input}{{12}{12}{Grayscale image of number 7 (4 x 4 pixels resolution)}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Regular neural network recognizing number 7 in image input from \autoref  {fig:input}, which is deconstructed (flattened) into vector of size 16.}}{12}{figure.13}}
\newlabel{fig:regular_net_image}{{13}{12}{Regular neural network recognizing number 7 in image input from \autoref {fig:input}, which is deconstructed (flattened) into vector of size 16}{figure.13}{}}
\citation{lecun_object}
\citation{rgb_def}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces A number from \autoref  {fig:input} divided into four pixel regions.}}{13}{figure.14}}
\newlabel{fig:segmented_input}{{14}{13}{A number from \autoref {fig:input} divided into four pixel regions}{figure.14}{}}
\newlabel{eq:relu}{{13}{13}{Introduction to Convolutional Neural Networks}{equation.6.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Local connectivity of inputs from \autoref  {fig:segmented_input} to hidden nodes (vector form).}}{14}{figure.15}}
\newlabel{fig:cnn_column}{{15}{14}{Local connectivity of inputs from \autoref {fig:segmented_input} to hidden nodes (vector form)}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Local connectivity of inputs from \autoref  {fig:segmented_input} to hidden nodes (matrix form).}}{14}{figure.16}}
\newlabel{fig:cnn_spacial}{{16}{14}{Local connectivity of inputs from \autoref {fig:segmented_input} to hidden nodes (matrix form)}{figure.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces LeNet-5 CNN \cite  {lecun_object} used for handwritten digit recognition.}}{14}{figure.17}}
\newlabel{fig:lecun_net}{{17}{14}{LeNet-5 CNN \cite {lecun_object} used for handwritten digit recognition}{figure.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Consecutive steps of convolution using filter of size 2x2 with stride 2 (coefficients visible in red in the bottom right corner of a filter). The pink matrix is called a feature map and in this case represents a convolutional layer.}}{15}{figure.18}}
\newlabel{fig:convolution}{{18}{15}{Consecutive steps of convolution using filter of size 2x2 with stride 2 (coefficients visible in red in the bottom right corner of a filter). The pink matrix is called a feature map and in this case represents a convolutional layer}{figure.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Consecutive steps of max pooling with window of size 2x2 and stride 2. Green matrix is a reduced tensor.}}{15}{figure.19}}
\newlabel{fig:max_pooling}{{19}{15}{Consecutive steps of max pooling with window of size 2x2 and stride 2. Green matrix is a reduced tensor}{figure.19}{}}
\citation{synset_def}
\citation{canziani_analysis}
\citation{canziani_analysis}
\citation{canziani_analysis}
\citation{canziani_analysis}
\@writefile{toc}{\contentsline {section}{\numberline {7}Comparison of world-class CNN architectures}{16}{section.7}}
\newlabel{comparison_ccn_archs}{{7}{16}{Comparison of world-class CNN architectures}{section.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Comparison of world-class CNN architectures \cite  {canziani_analysis} including: top-1 accuracy, number of operations and parameters.}}{16}{figure.20}}
\newlabel{fig:world_cnns}{{20}{16}{Comparison of world-class CNN architectures \cite {canziani_analysis} including: top-1 accuracy, number of operations and parameters}{figure.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Transfer learning}{17}{section.8}}
\newlabel{transfer_learning}{{8}{17}{Transfer learning}{section.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Advanced CNN without last fully connected layer.}}{17}{figure.21}}
\newlabel{fig:tl_sliced_net}{{21}{17}{Advanced CNN without last fully connected layer}{figure.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Inference of one image (pink matrix) from training set using advanced CNN with sliced layer and pre-trained weights. The output (green vector) is a bottleneck feature i. e. this CNN's representation of a given image.}}{18}{figure.22}}
\newlabel{fig:obtain_bottleneck}{{22}{18}{Inference of one image (pink matrix) from training set using advanced CNN with sliced layer and pre-trained weights. The output (green vector) is a bottleneck feature i. e. this CNN's representation of a given image}{figure.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Inference in second (mediocre) neural network used in transfer learning, which is trained on labeled bottleneck features, with labeling illustrated below.}}{18}{figure.23}}
\newlabel{fig:using_bottleneck}{{23}{18}{Inference in second (mediocre) neural network used in transfer learning, which is trained on labeled bottleneck features, with labeling illustrated below}{figure.23}{}}
\citation{hsv_def}
\@writefile{toc}{\contentsline {section}{\numberline {9}Data augmentation}{19}{section.9}}
\newlabel{data_augmentation}{{9}{19}{Data augmentation}{section.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Data augmentation applied on a single STOP sign image.}}{19}{figure.24}}
\newlabel{fig:augm_ex}{{24}{19}{Data augmentation applied on a single STOP sign image}{figure.24}{}}
\newlabel{eq:horizontal_shear}{{14}{19}{Data augmentation}{equation.9.14}{}}
\newlabel{eq:vertical_shear}{{15}{19}{Data augmentation}{equation.9.15}{}}
\citation{retrofit_repo}
\citation{rxjava_repo}
\citation{kotlin_blogpost}
\citation{nosql_def}
\citation{rest_def}
\@writefile{toc}{\contentsline {section}{\numberline {10}Solution walkthrough}{20}{section.10}}
\newlabel{solution_walkthrough}{{10}{20}{Solution walkthrough}{section.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Main screen of Android application. Note the hints given to the user, resulting from prototype's limitations, namely: poor support of advanced searching in Firebase Realtime Database and high risk of wrong prediction given beer label image with a lot of background.}}{21}{figure.25}}
\newlabel{fig:app}{{25}{21}{Main screen of Android application. Note the hints given to the user, resulting from prototype's limitations, namely: poor support of advanced searching in Firebase Realtime Database and high risk of wrong prediction given beer label image with a lot of background}{figure.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Firebase Realtime Database with encoded key-value pairs of beer information.}}{21}{figure.26}}
\newlabel{fig:firebase_data}{{26}{21}{Firebase Realtime Database with encoded key-value pairs of beer information}{figure.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Terminal view of requests sent to Flask server (to "/predict" endpoint) from Android application. "200" return code indicates that request succeeded.}}{22}{figure.27}}
\newlabel{fig:terminal_server}{{27}{22}{Terminal view of requests sent to Flask server (to "/predict" endpoint) from Android application. "200" return code indicates that request succeeded}{figure.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Regular fully-connected neural network, which accuracy increased due to transfer learning based on Inception-V3. Values in brackets represent amount of neurons in each layer. Whereas number of neurons in hidden layers (f. c. layers) is fixed, inputs and outputs depend, respectively, on size of bottleneck features coming from Inception-V3 and number of beers CNN can recognize (in basic version of prototype it's 10). Both hidden layers use ReLU activation function.}}{22}{figure.28}}
\newlabel{fig:worse_net}{{28}{22}{Regular fully-connected neural network, which accuracy increased due to transfer learning based on Inception-V3. Values in brackets represent amount of neurons in each layer. Whereas number of neurons in hidden layers (f. c. layers) is fixed, inputs and outputs depend, respectively, on size of bottleneck features coming from Inception-V3 and number of beers CNN can recognize (in basic version of prototype it's 10). Both hidden layers use ReLU activation function}{figure.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Testing}{23}{section.11}}
\newlabel{testing}{{11}{23}{Testing}{section.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Manually collected data set for \foreignlanguage  {polish}{Harna\IeC {\'s}} beer label class. The first picture (2160 x 3840 pixels resolution) was taken by camera and the second one (ideal) was found on the internet.}}{23}{figure.29}}
\newlabel{fig:collected_labels}{{29}{23}{Manually collected data set for \foreignlanguage {polish}{Harnaś} beer label class. The first picture (2160 x 3840 pixels resolution) was taken by camera and the second one (ideal) was found on the internet}{figure.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Small portion of augmented training set for \foreignlanguage  {polish}{Harna\IeC {\'s}} beer label class.}}{23}{figure.30}}
\newlabel{fig:augm_subset}{{30}{23}{Small portion of augmented training set for \foreignlanguage {polish}{Harnaś} beer label class}{figure.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Accuracy of 10-class model during training. The best obtained value is 99.5\% for training set and 89.1\% for validation set.}}{24}{figure.31}}
\newlabel{fig:10_class_acc}{{31}{24}{Accuracy of 10-class model during training. The best obtained value is 99.5\% for training set and 89.1\% for validation set}{figure.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Categorical cross entropy error during training of 10-class CNN. The best obtained value is 0.051 for training set and 1.796 for validation set.}}{24}{figure.32}}
\newlabel{fig:10_class_err}{{32}{24}{Categorical cross entropy error during training of 10-class CNN. The best obtained value is 0.051 for training set and 1.796 for validation set}{figure.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Test results for 10-class CNN (different lighting conditions and background visibility of input image).}}{25}{figure.33}}
\newlabel{fig:test_table}{{33}{25}{Test results for 10-class CNN (different lighting conditions and background visibility of input image)}{figure.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Accuracy of 20-class model during training. The best obtained value is 99.8\% for training set and 87.6\% for validation set.}}{26}{figure.34}}
\newlabel{fig:20_class_acc}{{34}{26}{Accuracy of 20-class model during training. The best obtained value is 99.8\% for training set and 87.6\% for validation set}{figure.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Categorical cross entropy error during training of 20-class CNN. The best obtained value is 0.017 for training set and 1.16 for validation set.}}{26}{figure.35}}
\newlabel{fig:20_class_err}{{35}{26}{Categorical cross entropy error during training of 20-class CNN. The best obtained value is 0.017 for training set and 1.16 for validation set}{figure.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12}Conclusions}{27}{section.12}}
\newlabel{conclusions}{{12}{27}{Conclusions}{section.12}{}}
\bibdata{mybib}
\bibcite{hsv_def}{1}
\bibcite{kotlin_blogpost}{2}
\bibcite{nosql_def}{3}
\bibcite{rest_def}{4}
\bibcite{retrofit_repo}{5}
\bibcite{rxjava_repo}{6}
\bibcite{synset_def}{7}
\bibcite{android_guide}{8}
\bibcite{firebase_database_docs}{9}
\bibcite{flask_docs}{10}
\bibcite{survey}{11}
\bibcite{cpu_vs_gpu}{12}
\bibcite{chain_rule_def}{13}
\bibcite{rgb_def}{14}
\bibcite{canziani_analysis}{15}
\bibcite{cisco_era}{16}
\bibcite{kpmg_alco}{17}
\bibcite{lecun_object}{18}
\bibcite{lowe_sift}{19}
\bibcite{ai_modern_approach}{20}
\bibcite{barcode_mobile}{21}
\bibcite{lean_startup}{22}
\bibcite{beer_sift}{23}
\bibstyle{siam}
